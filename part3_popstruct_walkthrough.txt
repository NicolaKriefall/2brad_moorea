#from https://github.com/z0on/2bRAD_denovo/blob/master/2bRAD_README.txt
#^^find instructions for downloading scripts & packages at this link^^
#edits by Nicola Kriefall thenicolakriefall(at)gmail.com

#===================== A  N  G  S  D =====================

# "FUZZY genotyping" with ANGSD - without calling actual genotypes but working with genotype likelihoods at each SNP. Optimal for low-coverage data (<10x).

# listing all bam filenames 
ls *bam > bams

#--------------- finding clones

# Note: PCA and Admixture are not supposed to be run on data that contain clones or genotyping replicates. For PCA, these can be removed without rerunning ANGSD from the IBS distance matrix; but for ngsAdmix ANGSD must be rerun.
# for my first run through, keeping all samples, will remove clones & genotyping replicates for second run-through

# Generating genotype likelihoods from highly confident (non-sequencing-error) SNPs
# set minInd to 75-80% of your total number of bams [I did ~80%, 109 samples out of 136 total]
# if you expect very highly differentiated populations with nearly fixed alternative alleles, remove '-hwe_pval 1e-5' from FILTERS
# -doGeno 8 : genotype likelihood format setting for ngsLD; if you want to run PCA, use -doGeno 32 (but I recommend using ibsMat for all ordination work)

# Starting angsd with -P the number of parallel processes. Funny but in many cases angsd runs faster on -P 1
nano angsd.sh
# add the following text to .sh:
#!/bin/bash -l
#$ -V # inherit the submission environment
#$ -cwd #start job in submission directory
#$ -N angsd.sh # job name, anything you want
#$ -l h_rt=24:00:00
#$ -M thenicolakriefall@gmail.com
#$ -m be
FILTERS="-uniqueOnly 1 -remove_bads 1 -minMapQ 20 -minQ 25 -dosnpstat 1 -doHWE 1 -sb_pval 1e-5 -hetbias_pval 1e-5 -skipTriallelic 1 -minInd 91 -snp_pval 1e-5 -minMaf 0.1 -minIndDepth 8 -hwe_pval 1e-5"
TODO="-doMajorMinor 1 -doMaf 1 -doCounts 1 -makeMatrix 1 -doIBS 1 -doCov 1 -doGeno 8 -doVcf 1 -doPost 1 -doGlf 2 -dumpCounts 2"
angsd -b bams -GL 1 $FILTERS $TODO -P 1 -out myresult
#exit & save

qsub angsd.sh

# use IBS results to look for clones & technical replicates for removal
# sftp (or some other transfer method) to file transfer 'myresult.ibsMat' & 'bams' to your local computer
# use part3_ibs_findclones.R to see results

# Assessing average site depth coverage per sample using vcftools:
gunzip myresult.vcf.gz
# You have to do this strange thing where you remove "(angsd version)" from the header of your vcf file, or else vcftools won't work
nano myresult.vcf
#first line reads:
##fileformat=VCFv4.2(angsd version)
# manually delete "(angsd version)" from this line so it just reads "VCFv4.2"
#exit & save

module load vcftools
vcftools --vcf myresult.vcf.gz --depth
#results (mean depth of sites per individual) are in a file ending in '.idepth'

#after looking at my sample's depths, I decided to get rid of samples with less than an average of 8 reads for my final analysis, increases the number of reliable SNPs you get from the total dataset
#also removed technical replicates/clones from 'bams' file & saved it as 'bams_no8'

#re-running ANGSD without clones & without poorly covered samples:
nano angsd_donish.sh
# added the following text to .sh:
#!/bin/bash -l
#$ -V # inherit the submission environment
#$ -cwd #start job in submission directory
#$ -N angsd_donish.sh # job name, anything you want
#$ -l h_rt=24:00:00
#$ -M thenicolakriefall@gmail.com
#$ -m be
FILTERS="-uniqueOnly 1 -remove_bads 1 -minMapQ 20 -minQ 25 -dosnpstat 1 -doHWE 1 -sb_pval 1e-5 -hetbias_pval 1e-5 -skipTriallelic 1 -minInd 91 -snp_pval 1e-5 -minMaf 0.1 -minIndDepth 8 -hwe_pval 1e-5"
TODO="-doMajorMinor 1 -doMaf 1 -doCounts 1 -makeMatrix 1 -doIBS 1 -doCov 1 -doGeno 8 -doVcf 1 -doPost 1 -doGlf 2 -dumpCounts 2"
angsd -b bams_no8 -GL 1 $FILTERS $TODO -P 1 -out donresult
#exit & save

qsub angsd_donish.sh

#transferred .vcf and new bams_no8 file to local working directory to use in 'part3_plotting_popstruct.R'

how many SNPs?
NSITES=`zcat donresult.mafs.gz | wc -l`
echo $NSITES
#I had 5350 sites

# LD: (use rEM for WGCNA, to look for signatures of polygenic selection):
module load gsl
NS=`zcat myresult.geno.gz | wc -l`
NB=`cat bams_no8 | wc -l`
zcat someresult.mafs.gz | tail -n +2 | cut -f 1,2 > some.sites
ngsLD --geno someresult.geno.gz --probs 1 --n_ind $NB --n_sites $NS --max_kb_dist 0 --pos some.sites --out some.LD --n_threads 12 --extend_out 1
#max_kb_dist set to 0 means it will do all pairwise comparisons

#to remove linked sites:
module load ngsld
module load perl

nano prune.sh
#!/bin/bash -l
#$ -V # inherit the submission environment
#$ -cwd #start job in submission directory
#$ -N prune.sh # job name, anything you want
#$ -l h_rt=24:00:00
#$ -M thenicolakriefall@gmail.com
#$ -m be
prune_graph.pl --in_file some.ld --max_kb_dist 5 --min_weight 0.5 --out some_unlinked.id

#exit nano
qsub prune.sh

#generated unlinked file - not sure how to get it out of my data yet
#angsd sites indexing not working

# NgsAdmix for K from 2 to 5 : do not run if the dataset contains clones or genotyping replicates!
for K in `seq 2 5` ; 
do 
NGSadmix -likes someresult.beagle.gz -K $K -P 10 -o some_k${K};
done

# alternatively, to use real ADMIXTURE on called SNPs (requires plink and ADMIXTURE):
gunzip someresult.vcf.gz

module load plink/1.90b6.4
module load admixture

plink --vcf donresult.vcf.gz --make-bed --allow-extra-chr 0 --out done
for K in `seq 1 5`; \
do admixture --cv done.bed $K | tee done_${K}.out; done

# which K is least CV error?
grep -h CV done_*.out

#CV error (K=1): 0.60678
#CV error (K=2): 0.62188
#CV error (K=3): 0.64356
#CV error (K=4): 0.66027
#CV error (K=5): 0.67737

# scp the *.Q and inds2pops files to laptop, plot it in R:
# use part3_plotting_popstruct.R to plot (will require minor editing - population names)

#### Fst things

export GENOME_REF=./Amil.fasta

# per each population, generate saf.idx file 

#ST_J 
FILTERS="-uniqueOnly 1 -remove_bads 1 -minMapQ 30 -minQ 30 -minInd 38 -dosnpstat 1 -doHWE 1 -hwe_pval 1e-5 -sb_pval 1e-5 -hetbias_pval 1e-5"
TODO="-doSaf 1 -doMajorMinor 1"
echo "angsd -b ST_J -GL 1 -anc $GENOME_REF -nInd 48 $FILTERS $TODO -P 1 -out STJ_freq" > freq
ls5_launcher_creator.py -j freq -n freq -l allele_freq -t 2:00:00 -w 1 -A tagmap 
sbatch allele_freq


#ST_A  
FILTERS="-uniqueOnly 1 -remove_bads 1 -minMapQ 30 -minQ 30 -minInd 27 -dosnpstat 1 -doHWE 1 -hwe_pval 1e-5 -sb_pval 1e-5 -hetbias_pval 1e-5"
TODO="-doSaf 1 -doMajorMinor 1"
echo "angsd -b ST_A -GL 1 -anc $GENOME_REF -nInd 34 $FILTERS $TODO -P 1 -out STA_freq" > freq2
ls5_launcher_creator.py -j freq2 -n freq2 -l allele_freq2 -t 2:00:00 -w 1 -A tagmap 
sbatch allele_freq2

#calculate the 2dsfs prior 

echo "realSFS STA_freq.saf.idx STA_freq.saf.idx > ST_AJ.ml" > sfs 
ls5_launcher_creator.py -j sfs -n sfs -l sfs_1 -t 1:00:00 -w 1 -A tagmap 


#####	prepare the fst for easy window analysis etc 	#########

echo "realSFS fst index STJ_freq.saf.idx STA_freq.saf.idx -sfs ST.ml -fstout SThere" > here
ls5_launcher_creator.py -j here -n here -l hereST -t 1:00:00 -w 1 -A tagmap 


#####    getting the global Fst estimate    #######

realSFS fst stats SThere.fst.idx



#### calculating theta #### 

echo "realSFS STJ_freq_fold.saf.idx > stj.sfs" > sfs
ls5_launcher_creator.py -j sfs -n sfs -l sfs_job -t 1:00:00 -w 1 -A tagmap 

echo "realSFS STA_freq_fold.saf.idx > sta.sfs" > sfs
ls5_launcher_creator.py -j sfs -n sfs -l sfs_job -t 1:00:00 -w 1 -A tagmap 


## if your reference genome is not the same as your study species, then use -anc for the genome ref 

TODO="-doSaf 1 -doThetas 1 -fold 1" 
echo "angsd -b ST_J -out STJ_theta -pest stj.sfs -anc $GENOME_REF $TODO -GL 1"> theta
ls5_launcher_creator.py -j theta -n theta -l thetajob -t 1:00:00 -w 1 -A tagmap 

TODO="-doSaf 1 -doThetas 1 -fold 1" 
echo "angsd -b ST_A -out STA_theta -pest sta.sfs -anc $GENOME_REF $TODO -GL 1"> theta
ls5_launcher_creator.py -j theta -n theta -l thetajob -t 1:00:00 -w 1 -A tagmap 

 
#global theta estimate for every Chromosome/scaffold
#thetaStat is an angsd subprogram, so it should be installed already with angsd 

thetaStat do_stat STA_theta.thetas.idx

## sliding window analysis of theta with 50000 kb window with 10000 kb step size if interested in regions of high/low diversity

thetaStat do_stat STJ_theta.thetas.idx -win 50000 -step 10000  -outnames STJ.theta
thetaStat do_stat STA_theta.thetas.idx -win 50000 -step 10000  -outnames STA.theta