#from https://github.com/z0on/2bRAD_denovo/blob/master/2bRAD_README.txt
#^^find instructions for downloading scripts & packages at this link^^
#edits by Nicola Kriefall thenicolakriefall(at)gmail.com

#===================== A  N  G  S  D =====================

# "FUZZY genotyping" with ANGSD - without calling actual genotypes but working with genotype likelihoods at each SNP. Optimal for low-coverage data (<10x).

# listing all bam filenames 
ls *bam > bams

#--------------- population structure

# Note: PCA and Admixture are not supposed to be run on data that contain clones or genotyping replicates. For PCA, these can be removed without rerunning ANGSD from the IBS distance matrix; but for ngsAdmix ANGSD must be rerun.

# Generating genotype likelihoods from highly confident (non-sequencing-error) SNPs
# set minInd to 75-80% of your total number of bams [I did ~80%, 109 samples out of 136 total]
# if you expect very highly differentiated populations with nearly fixed alternative alleles, remove '-hwe_pval 1e-5' from FILTERS
# -doGeno 8 : genotype likelihood format setting for ngsLD; if you want to run PCA, use -doGeno 32 (but I recommend using ibsMat for all ordination work)

# Starting angsd with -P the number of parallel processes. Funny but in many cases angsd runs faster on -P 1
nano angsd.sh
# add the following text to .sh:
#!/bin/bash -l
#$ -V # inherit the submission environment
#$ -cwd #start job in submission directory
#$ -N angsd.sh # job name, anything you want
#$ -l h_rt=24:00:00
#$ -M thenicolakriefall@gmail.com
#$ -m be
FILTERS="-uniqueOnly 1 -remove_bads 1 -minMapQ 20 -minQ 25 -dosnpstat 1 -doHWE 1 -sb_pval 1e-5 -hetbias_pval 1e-5 -skipTriallelic 1 -minInd 109 -snp_pval 1e-5 -minMaf 0.1 -minIndDepth 5 -hwe_pval 1e-5"
TODO="-doMajorMinor 1 -doMaf 1 -doCounts 1 -makeMatrix 1 -doIBS 1 -doCov 1 -doGeno 8 -doVcf 1 -doPost 1 -doGlf 2 -dumpCounts 2"
angsd -b bams -GL 1 $FILTERS $TODO -P 1 -out myresult
#exit & save

qsub angsd.sh

# use IBS results to look for clones & technical replicates for removal
# sftp (or some other transfer method) to file transfer 'myresult.ibsMat' & 'bams' to your local computer
# use part3_ibs_findclones.R to see results

# Assessing average site depth coverage per sample using vcftools:
gunzip myresult.vcf.gz
# You have to do this strange thing where you remove "(angsd version)" from the header of your vcf file, or else vcftools won't work
nano myresult.vcf
#first line reads:
##fileformat=VCFv4.2(angsd version)
# manually delete "(angsd version)" from this line so it just reads "VCFv4.2"
#exit & save

module load vcftools
vcftools --vcf myresult.vcf.gz --depth
#results (mean depth of sites per individual) are in a file ending in '.idepth'

#after looking at my sample's depths, I decided to get rid of samples with less than an average of 8 reads for my final analysis, increases the number of reliable SNPs you get from the total dataset
#also removed technical replicates/clones from 'bams' file & saved it as 'bams_no8'

#re-running ANGSD without clones & without poorly covered samples:
nano angsd_donish.sh
# added the following text to .sh:
#!/bin/bash -l
#$ -V # inherit the submission environment
#$ -cwd #start job in submission directory
#$ -N angsd_donish.sh # job name, anything you want
#$ -l h_rt=24:00:00
#$ -M thenicolakriefall@gmail.com
#$ -m be
FILTERS="-uniqueOnly 1 -remove_bads 1 -minMapQ 20 -minQ 25 -dosnpstat 1 -doHWE 1 -sb_pval 1e-5 -hetbias_pval 1e-5 -skipTriallelic 1 -minInd 91 -snp_pval 1e-5 -minMaf 0.1 -minIndDepth 8 -hwe_pval 1e-5"
TODO="-doMajorMinor 1 -doMaf 1 -doCounts 1 -makeMatrix 1 -doIBS 1 -doCov 1 -doGeno 8 -doVcf 1 -doPost 1 -doGlf 2 -dumpCounts 2"
angsd -b bams_no8 -GL 1 $FILTERS $TODO -P 1 -out donresult
#exit & save

qsub angsd_donish.sh

#transferred .vcf and new bams_no8 file to local working directory to use in 'part3_plotting_vcf.R'

how many SNPs?
NSITES=`zcat donresult.mafs.gz | wc -l`
echo $NSITES
#I had 5350 sites

# LD: (use rEM for WGCNA, to look for signatures of polygenic selection):
module load gsl
NS=`zcat myresult.geno.gz | wc -l`
NB=`cat bams_no8 | wc -l`
zcat someresult.mafs.gz | tail -n +2 | cut -f 1,2 > some.sites
ngsLD --geno someresult.geno.gz --probs 1 --n_ind $NB --n_sites $NS --max_kb_dist 0 --pos some.sites --out some.LD --n_threads 12 --extend_out 1
#max_kb_dist set to 0 means it will do all pairwise comparisons

#to remove linked sites:
module load ngsld
module load perl

nano prune.sh
#!/bin/bash -l
#$ -V # inherit the submission environment
#$ -cwd #start job in submission directory
#$ -N prune.sh # job name, anything you want
#$ -l h_rt=24:00:00
#$ -M thenicolakriefall@gmail.com
#$ -m be
prune_graph.pl --in_file some.ld --max_kb_dist 5 --min_weight 0.5 --out some_unlinked.id

#exit nano
qsub prune.sh

#generated unlinked file - not sure how to get it out of my data yet
#angsd sites indexing not working

# NgsAdmix for K from 2 to 5 : do not run if the dataset contains clones or genotyping replicates!
for K in `seq 2 5` ; 
do 
NGSadmix -likes someresult.beagle.gz -K $K -P 10 -o some_k${K};
done

# alternatively, to use real ADMIXTURE on called SNPs (requires plink and ADMIXTURE):
gunzip someresult.vcf.gz

module load plink/1.90b6.4
module load admixture

plink --vcf someresult.vcf --make-bed --allow-extra-chr 0 --out some
for K in `seq 1 5`; \
do admixture --cv some.bed $K | tee some_${K}.out; done

# which K is least CV error?
grep -h CV some_*.out

# scp the *.Q and inds2pops files to laptop, plot it in R:
# use admixturePlotting2a.R to plot (will require minor editing - population names)

# scp *Mat, *qopt and bams files to laptop, use 

# relatedness (must run ANGSD with option '-doGlf 3' to make this work)
# (column "rab" in the result is relatedness coefficient, Fa and Fb are individual inbreeding coefficients):
zcat myresult.mafs.gz | cut -f5 |sed 1d >freq
NIND=`cat bams | wc -l`
ngsRelate -f freq -g myresult.glf.gz -n $NIND -z bams >relatedness

bads=c("K4","O5","K211","K212","K210","K213","K219")
